{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilibili Converter\n",
    "## 1.爬取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,json,time\n",
    "def loadJson(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        fileData = json.load(f)\n",
    "    return fileData\n",
    "\n",
    "def writeJson(name,path,isFormat=True):\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        if isFormat:\n",
    "            f.write(json.dumps(name,ensure_ascii=False,indent=2))\n",
    "        else:\n",
    "            f.write(json.dumps(name))\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里可以得到某个频道的所有播放大于5万的历史视频。   \n",
    "但是你需要提供该频道的id和你自己得到的offset。  \n",
    "具体的方式是：打开你需要的频道，F12查看api请求，找到下面对应的api即可知道所需的offset（不填offset能不能用没测试过）频道id直接在url就可以看到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8144/3644140808.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://api.bilibili.com/x/web-interface/web/channel/multiple/list?channel_id=1393143&sort_type=hot&offset={}&page_size=30\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mallVideo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "allVideo = []\n",
    "offset = \"428583780_1658362131\"\n",
    "id = \"1393143\"\n",
    "for i in range(500):\n",
    "    url = \"https://api.bilibili.com/x/web-interface/web/channel/multiple/list?channel_id={}&sort_type=hot&offset={}&page_size=30\".format(id,offset)\n",
    "    time.sleep(0.5)\n",
    "    data = requests.get(url=url).json()\n",
    "    allVideo.extend(data['data']['list'])\n",
    "    offset = data['data']['offset']\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    if not data['data']['has_more']:\n",
    "        break\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存你爬取到的频道视频信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeJson(allVideo,\"allvideo.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于视频信息不够完整，我们需要得到一些视频的基础信息，这里要用到另一个api读取基础信息，以及访问网页本体得到时间信息和tag信息。可根据自己需要选取，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "baseInfoList = []\n",
    "timeList = []\n",
    "tagList = []\n",
    "dic_header = {'User-Agent':'Mozilla/5.0'}\n",
    "def get_base_info(aid):\n",
    "    base_info_url = f'https://api.bilibili.com/x/web-interface/archive/stat?aid={aid}'\n",
    "    base_info = {}\n",
    "    try:\n",
    "        base_info = requests.get(base_info_url,headers=dic_header).json()['data']\n",
    "        #print('播放量：{}\\n弹幕数量：{}\\n收藏数量：{}\\n硬币数量：{}\\n分享数量：{}\\n点赞数量：{}\\n-----\\n评论数量：{}'.format(\n",
    "    except:\n",
    "        print('Error')\n",
    "    return base_info\n",
    "def get_title_time_tag(bvid):\n",
    "    tag_lst = []\n",
    "    url = f'https://www.bilibili.com/video/{bvid}'\n",
    "    content = requests.get(url).content\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    tags = soup.find_all('a',class_='tag-link')\n",
    "    title_lst = soup.find_all('title')\n",
    "    title = title_lst[0].text.split('_')[0]\n",
    "    time_lst = soup.find_all(itemprop='uploadDate')\n",
    "    if(len(time_lst)>0):\n",
    "        time = time_lst[0]['content'].split(' ')[0]\n",
    "    else:\n",
    "        time = \"error\"\n",
    "    for tag in tags:\n",
    "        tag_lst.append(tag.text.strip())\n",
    "    return title,time,list(set(tag_lst))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "newVideoList = []\n",
    "errorList = []\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n"
     ]
    }
   ],
   "source": [
    "allVideo = loadJson(\"newAllVideo.json\")\n",
    "recordCount = 0 #如果你中途断掉了，可以改recordCount到你断掉的点，继续进行下载\n",
    "count = 0\n",
    "import time,random\n",
    "for i in range(len(allVideo)):\n",
    "    if count >= recordCount:      \n",
    "        baseInfo = get_base_info(allVideo[i]['metaData']['id'])\n",
    "        time.sleep(1+random.random())\n",
    "        \n",
    "        if(type(baseInfo)==None):\n",
    "            errorList.append(allVideo[i])  \n",
    "        allVideo[i]['baseInfo']=baseInfo  \n",
    "        if count % 100 == 0:\n",
    "            print(count)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeJson(allVideo,\"newAllVideo2.json\") #保存完整的视频信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据转化\n",
    "将原始json数据转化为可用的csv\n",
    "### 时间顺序显示视频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "f = open(\"./allVideo.csv\",\"w\",encoding=\"utf-8-sig\",newline='')\n",
    "writer = csv.writer(f)\n",
    "line = ['name','type','value','date']\n",
    "writer.writerow(line)\n",
    "for video in allVideo:\n",
    "    line = []\n",
    "    if video['baseInfo'] != None:\n",
    "        if video['baseInfo']['copyright']==1:\n",
    "            line = [video['metaData']['name'],video['metaData']['author_name'],video['baseInfo']['view'],video['time']]\n",
    "            # csv.writer()中可以传一个文件对象\n",
    "            writer.writerow(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据视频信息制作作者排行榜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metaData': {'id': 51929624, 'name': '【Undertale AU】各路审判曲完整版合集（2.26更新到123P）', 'cover': 'http://i1.hdslb.com/bfs/archive/0187d9cb95ae138caacec4ef2f63a383aeccfcbe.jpg', 'view_count': '31.6万', 'like_count': '7220', 'duration': '7:02:20', 'author_name': '永神ヽ幽鸾', 'author_id': 397236985, 'bvid': 'BV1P4411Y7BD', 'danmaku': 6771, 'card_type': 'archive', 'sort': 'hot', 'filt': 0}, 'baseInfo': None, 'tag': [], 'time': ''}\n",
      "{'metaData': {'id': 27089874, 'name': '【中文字幕】【undertale音乐剧】狂妄之人-最终の审判', 'cover': 'http://i1.hdslb.com/bfs/archive/4ecfe14b22606a9bb098c57ef77ff514d3c511eb.jpg', 'view_count': '39.7万', 'like_count': '8183', 'duration': '7:25', 'author_name': '账号已注销', 'author_id': 87148129, 'bvid': 'BV1As411E7tU', 'danmaku': 650, 'card_type': 'archive', 'sort': 'hot', 'filt': 0}, 'baseInfo': None, 'tag': [], 'time': ''}\n",
      "{'metaData': {'id': 27019526, 'name': 'Undertale 传说之下 Megalovania Toby Fox [piano]', 'cover': 'http://i1.hdslb.com/bfs/archive/f85bfaab2f93267cfd07fd291e03ee805bd182b4.jpg', 'view_count': '10.5万', 'like_count': '1736', 'duration': '1:38', 'author_name': 'panpiano', 'author_id': 72956117, 'bvid': 'BV1rs41177rN', 'danmaku': 151, 'card_type': 'archive', 'sort': 'hot', 'filt': 0}, 'baseInfo': None, 'tag': [], 'time': ''}\n",
      "{'metaData': {'id': 15299869, 'name': '【undertale】转载-怪物们回到地上的优雅生活', 'cover': 'http://i2.hdslb.com/bfs/archive/cdae9ce8e66b4605504e08dd2de005e7463d5f27.jpg', 'view_count': '32.5万', 'like_count': '5736', 'duration': '1:05', 'author_name': 'PRATICLE_', 'author_id': 111233299, 'bvid': 'BV1Ux411u7pd', 'danmaku': 835, 'card_type': 'archive', 'sort': 'hot', 'filt': 0}, 'baseInfo': None, 'tag': [], 'time': ''}\n",
      "{'metaData': {'id': 7796049, 'name': 'Undertale [Genocide AMV Animation] - Last One Standing', 'cover': 'http://i1.hdslb.com/bfs/archive/4ef387cf6934c1587c22d61962a7b7f77f3ce149.jpg', 'view_count': '57.1万', 'like_count': '1万', 'duration': '3:25', 'author_name': 'Hanakawa_yuki', 'author_id': 10247190, 'bvid': 'BV1ws411Y7v5', 'danmaku': 602, 'card_type': 'archive', 'sort': 'hot', 'filt': 0}, 'baseInfo': None, 'tag': [], 'time': ''}\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "allVideo = loadJson(\"newAllVideo2.json\")\n",
    "allAuthor = []\n",
    "allAuthorCount = {}\n",
    "for video in allVideo:\n",
    "    try:\n",
    "        if video['metaData']['author_name'] not in allAuthor and video['baseInfo']['copyright']==1:\n",
    "            allAuthor.append(video['metaData']['author_name'])\n",
    "            allAuthorCount[video['metaData']['author_name']]=1\n",
    "        elif video['baseInfo']['copyright']==1:\n",
    "            allAuthorCount[video['metaData']['author_name']]+=1\n",
    "    except:\n",
    "        print(video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    }
   ],
   "source": [
    "filterAuthor = [] # 这里筛选掉视频少于一定数量的作者，减少非活跃的作者，避免出现”圈外人“。以及去掉难以进入排行榜的作者，加快计算速度。\n",
    "for k,v in allAuthorCount.items():\n",
    "    if v > 2 and k != '账号已注销':\n",
    "        filterAuthor.append(k)\n",
    "print(len(filterAuthor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metaData': {'id': 723291572, 'name': '【明日方舟新春会】感染者之盾', 'cover': 'http://i2.hdslb.com/bfs/archive/8bf8d6a3ed02caa4319bed5cc90968d5f9b491b1.jpg', 'badge_title': '精选', 'badge_background': 'http://i0.hdslb.com/bfs/tag/14f32b8a0f0002d16fdd57d3b8ddaf9e50f3c5fe.png', 'view_count': '66.8万', 'like_count': '5.6万', 'duration': '7:14', 'author_name': '阴险之鹰', 'author_id': 357423129, 'bvid': 'BV1VS4y1o7TV', 'danmaku': 915, 'card_type': 'archive', 'sort': 'hot', 'filt': 0}, 'baseInfo': {'aid': 723291572, 'bvid': 'BV1VS4y1o7TV', 'view': 668180, 'danmaku': 915, 'reply': 1029, 'favorite': 31388, 'coin': 48519, 'share': 8064, 'like': 55779, 'now_rank': 0, 'his_rank': 0, 'no_reprint': 1, 'copyright': 1, 'argue_msg': '', 'evaluation': ''}, 'tag': [], 'time': 'error'}\n"
     ]
    }
   ],
   "source": [
    "# 得到所有筛选过作者的视频，并排序得到最小时间和最大时间（因为原js脚本没有插值功能）\n",
    "viewDict = {}\n",
    "timeList = []\n",
    "for name in filterAuthor:\n",
    "    viewDict[name]=[]\n",
    "for video in allVideo:\n",
    "    if video['metaData']['author_name'] in filterAuthor:\n",
    "        try:\n",
    "            if(video['baseInfo']['copyright']==1):\n",
    "                unit = (video['baseInfo']['view'],datetime.datetime.strptime(video['time'],\"%Y-%m-%d\").timestamp())\n",
    "                viewDict[video['metaData']['author_name']].append(unit)\n",
    "                timeList.append(datetime.datetime.strptime(video['time'],\"%Y-%m-%d\").timestamp())\n",
    "        except:\n",
    "            print(\"这条视频没有时间信息？:\"+video)\n",
    "\n",
    "timeList.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将视频播放量视为增量，转化为总量\n",
    "endTime=timeList[-1]\n",
    "for k,v in viewDict.items():\n",
    "    viewDict[k]=sorted(v,key=lambda v : v[1])\n",
    "    totalView = 0\n",
    "    for i in range(len(viewDict[k])):\n",
    "        viewDict[k][i]=list(viewDict[k][i])\n",
    "        viewDict[k][i][0]+=totalView\n",
    "        totalView=viewDict[k][i][0]\n",
    "    viewDict[k].append((viewDict[k][-1][0],endTime))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行插值处理\n",
    "import numpy as np\n",
    "viewDictF = {}\n",
    "\n",
    "isFirst = True\n",
    "for k,v in viewDict.items():\n",
    "    indexIn = []\n",
    "    valueIn = []\n",
    "    startTime = datetime.datetime.fromtimestamp(v[0][1])\n",
    "    endTime = datetime.datetime.fromtimestamp(v[-1][1])\n",
    "    \n",
    "    dayLen = (endTime-startTime).days+1\n",
    "    viewDictF[k]={}\n",
    "    viewDictF[k]['start']=startTime\n",
    "    viewDictF[k]['timeSeries']=np.full(dayLen,np.nan)\n",
    "    indexAll = [i for i in range(dayLen)]\n",
    "    for item in v:\n",
    "        index = (datetime.datetime.fromtimestamp(item[1])-startTime).days\n",
    "        viewDictF[k]['timeSeries'][index]=item[0]\n",
    "        indexIn.append(index)\n",
    "        valueIn.append(item[0])\n",
    "    #print(indexIn)\n",
    "    indexOut = list(set(indexAll)-set(indexIn))\n",
    "    interP = np.interp(indexOut, indexIn, valueIn)\n",
    "    viewDictF[k]['timeSeries'][indexOut]=interP\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储作者排行榜的csv\n",
    "import csv\n",
    "f = open(\"./allAuthor.csv\",\"w\",encoding=\"utf-8-sig\",newline='')\n",
    "writer = csv.writer(f)\n",
    "line = ['name','type','value','date']\n",
    "writer.writerow(line)\n",
    "for k,v in viewDictF.items():\n",
    "    for i in range(v['timeSeries'].shape[0]):\n",
    "        line = []\n",
    "        line = [k,k,v['timeSeries'][i],(v['start']+datetime.timedelta(days=i)).strftime(\"%Y-%m-%d\")]\n",
    "        # csv.writer()中可以传一个文件对象\n",
    "        writer.writerow(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c956479f3b7482fa07a98f39f62e99a84ef3fef46eab6bdcb0d3962625c2c4e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
